import pandas as pd

from matplotlib import pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.ensemble import RandomForestRegressor
from procesing import procces_df, count_time
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import MinMaxScaler

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, LeakyReLU
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import TimeSeriesSplit


if __name__ == '__main__':
   df_train1 = pd.read_csv('train_FD001.txt', delim_whitespace=True)
   df_train1 = procces_df(df_train1)

   df_test1 = pd.read_csv('test_FD001.txt', delim_whitespace=True)
   df_test1 = procces_df(df_test1)

   breakout_list = count_time(df_train1)





def custom_train_test_split(df, test_ratio):
     unique_units = df['unit number'].unique()
     num_test_units = int(len(unique_units) * test_ratio)

     num_test_units = min(num_test_units, len(unique_units))

     test_units = unique_units[:num_test_units]
     train_units = unique_units[num_test_units:]
     
     test = df[df['unit number'].isin(test_units)]
     train = df[df['unit number'].isin(train_units)]
     
     X_test_list, y_list_test = splitting(test, 'test')
     X_train, Y_train = splitting(train, 'train')
     print(f'y_test_list{y_list_test[0]}')

     return  X_train, X_test_list, Y_train, y_list_test


def splitting(df, type):
      
      if type == 'test2':


        
        X_test_list = []

        for unit in df['unit number'].unique():
             unit_data = df[df['unit number'] == unit]
             X_test_list.append(unit_data)
        return   X_test_list  

   
      X_list = []
      y_list = []
      num = 1

      for i in (df['unit number'].unique()):
                spectrum = breakout_list[i - 1] - np.random.randint(25, 80)
                filt = df['unit number'] == i
                df_filt = df[filt]
       

                x_todrop = df_filt['time'] <  spectrum
                y_todrop = df_filt['time'] >= spectrum
         

                x_filtered = df_filt[x_todrop]
                y_filtered = df_filt[y_todrop]

                y = y_filtered['time'].max()
                print(f'yyyyyyyyyyyyyyyy{y}')
                y_to_go = pd.Series([y] * x_filtered.shape[0], index=x_filtered.index)
                print(f'debugging y_to_go{y_to_go.max()}')

                X_list.append(x_filtered)
                y_list.append(y_to_go)
                print(num)
                num += 1
   
      X_comb = pd.concat(X_list, ignore_index=True)
      y_comb = pd.concat(y_list, ignore_index=True)

      if type == 'test':


        
        X_test_list = []

        for unit in X_comb['unit number'].unique():
             unit_data = X_comb[X_comb['unit number'] == unit]
             X_test_list.append(unit_data)

        print(f'debugging{y_list[0]}')
        y_list_mean = [(series.max()) for series in y_list]   
        print(f'y_list_mean{y_list_mean[0]}')   
        return X_test_list, y_list_mean 
      

      if type == 'train':
#        train
         return X_comb, y_comb

# if __name__ == '__main__':
# X, y = splitting(df_train1)

def pred_and_eve(model, test_list):
    
    y_pred_list = []

    for test in test_list:
            y_pred = model.predict(test)
            y_pred_list.append(np.mean(y_pred))

    return y_pred_list

def minmaxscaling_sequences(df, df_test, engines_range = 26):
     df = df.bfill()
    
     scaler = MinMaxScaler(feature_range=(0,1))
     features = df.columns.tolist()
     features.remove('unit number')
     features.remove('time')
     scaled_data = scaler.fit_transform(df[features])
     scaled_df_fake = pd.DataFrame(scaled_data)
     scaled_df = pd.concat([df['unit number'], df['time'],  scaled_df_fake], axis=1)
     scaled_df.columns = df.columns
    
           
     def create_sequences(data, engines_num):
          
        
          xs = []
          ys = []
        
          
          
          for engine_id in range(1, engines_num):
            # Filter data for the current engine
            print(F'ENGINE ID{engine_id}')
            filt = data['unit number'] == engine_id
            data_filt = data[filt]
           
            
            x = data_filt
            y = data_filt['time'].max() 
            y = np.array([y])
            y = y[np.newaxis, :]

            num_rows = len(x)
            group_size = 10
            num_full_groups = num_rows // group_size
            while num_full_groups % 5 != 0:
                  num_full_groups =  num_full_groups - 1 

                 

            x_sample = []
            

            print(f"Number of rows: {num_rows}")
            print(f"Number of full groups: {num_full_groups}")
            
          #  
            # Select only the rows that fit into full groups
            splited_x = x.iloc[:num_full_groups * group_size]

            print(f"Splitted data (x):")
            print(splited_x)
        
            group_start = 0
          
            for i in range(num_full_groups):
               
               splited_x2 = splited_x.iloc[group_start : group_start + group_size]
               splited_x2 = np.array(splited_x2)
               splited_x2 = splited_x2.reshape([1, 10, 148])
               x_sample.append(splited_x2)

               if len(x_sample) == 5:
                   xs.append(np.vstack(x_sample))
                   x_sample = []
                   ys.append(np.array([y] * 5))

              

               group_start += group_size  # Move to the start of the next group

            print(f"x_sample for engine {engine_id}:")
            print(x_sample)
        
            
              # Append the list of samples for this engine
                    # Append the maximum time for this engine
          
          
          
          
          return xs, ys


     return create_sequences(scaled_df, engines_num = engines_range)

# ERROR HERE############################################################################################################################
def LSTM_model(X_shape, y_shape):
     # RELU
     model = Sequential()
     model.add(LSTM(50, activation = 'relu', batch_input_shape=(5, X_shape, y_shape), stateful = True))
     model.add(Dense(1))
     model.compile(optimizer ='adam', loss = 'mse')

     # LEAKYRELU
     # model = Sequential()
     # model.add(LSTM(50, input_shape=(X_shape, y_shape), return_sequences = False))
     # model.add(LeakyReLU(alpha=0.3))
     # model.add(Dense(1))
     # model.compile(optimizer ='adam', loss = 'mse')

     return model


def model_fun(df, df_test, range_var, type = 'stateful'):
   X_train, y_train = minmaxscaling_sequences(df = df, df_test = df_test)

   if type == 'TimeSerSplit':

     mse_scores = []
     r2_scores = []
     tscv = TimeSeriesSplit(n_splits=3)
     for i in range(len(X_train)):
        for train_index, test_index in tscv.split(X_train[i]):
          X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]
          y_train_fold, y_test_fold = y_train[i] 

          # X_train_fold_padded
        
          model = LSTM_model(X_train_fold.shape[1], X_train_fold.shape[2])

          model_history = model.fit(X_train_fold, y_train_fold, epochs = 10, batch_size = 32, validation_split = 0.2)

          y_pred_fold = model.predict(X_test_fold)

          mse = mean_squared_error(y_test_fold, y_pred_fold)
          r2 = r2_score(y_test_fold, y_pred_fold)

          mse_scores.append(mse)
          r2_scores.append(r2)
   
          print(f'Unit {i} - Fold results:')
          print(f'  MSE: {mse}')
          print(f'  R2: {r2}')
     print(f'Average MSE: {np.mean(mse_scores)}')
     print(f'Average R2: {np.mean(r2_scores)}')    


   


   if type ==  'stateful': 
     sample_shape = np.array(X_train[0][0])
     print(sample_shape.shape)
     n_samples, n_features = sample_shape.shape
     print(sample_shape.shape)
    
     model = LSTM_model(n_samples, n_features)

     # X_train is a list with arrays that consist other arrays.
     # y_train is a list that consist 

     
     
     model_history = model.fit(X_train[0], y_train[0], epochs = 10)
 
     return model, model_history


def evaluate_LSTM_model(model, X_test):
     y_pred = model.predict(X_test[0])
    
     
     print(y_pred)
     print(F'NIEWIARYGONDE{y_pred.shape}')
     print(f'X_test{np.isnan(X_test[0]).sum()}')
     print(f'y_pred{np.isnan(y_pred[0]).sum()}')
     
     fig, ax = plt.subplots()
     xd = [1,22,3,4,5]
     # Plot the bar
     ax.bar('Prediction', xd, color='blue')

     # Label the plot
     ax.set_ylabel('Predicted Value')
     ax.set_title('Single Predicted Value')

     # Show the plot
     plt.show()

     
     stop = input('press anything to stop')


model, model_history = model_fun(df_train1, df_test1, range_var = 25, type = 'stateful')

X_test, y_test= minmaxscaling_sequences(df = df_test1, df_test = df_test1)

evaluate_LSTM_model(model = model, X_test = X_test)